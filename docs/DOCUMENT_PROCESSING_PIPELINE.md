# Document Processing Pipeline

–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤, –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—ó —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —É –≤–µ–∫—Ç–æ—Ä–Ω–∏—Ö —Å—Ö–æ–≤–∏—â–∞—Ö.

## üéØ –û–≥–ª—è–¥

–°–∏—Å—Ç–µ–º–∞ –∑–∞–±–µ–∑–ø–µ—á—É—î –ø–æ–≤–Ω–∏–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–æ–±–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤:

1. **–ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤** - –ø—ñ–¥—Ç—Ä–∏–º–∫–∞ PDF, DOCX, HTML, Markdown, TXT
2. **–ß–∞–Ω–∫—ñ–Ω–≥ —Ç–µ–∫—Å—Ç—É** - —Ä–æ–∑–±–∏—Ç—Ç—è –Ω–∞ –ª–æ–≥—ñ—á–Ω—ñ —á–∞—Å—Ç–∏–Ω–∏ –∑ —Ä—ñ–∑–Ω–∏–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è–º–∏
3. **–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è** - –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –µ–º–±–µ–¥–∏–Ω–≥—ñ–≤ –∑ –∫–µ—à—É–≤–∞–Ω–Ω—è–º —Ç–∞ –±–∞—Ç—á–µ–≤–æ—é –æ–±—Ä–æ–±–∫–æ—é
4. **–í–µ–∫—Ç–æ—Ä–Ω—ñ —Å—Ö–æ–≤–∏—â–∞** - –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ç–∞ –ø–æ—à—É–∫ –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é —Ä—ñ–∑–Ω–∏—Ö –±–µ–∫–µ–Ω–¥—ñ–≤

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞

```
src/data_pipeline/
‚îú‚îÄ‚îÄ document_processing/          # –û–±—Ä–æ–±–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
‚îÇ   ‚îú‚îÄ‚îÄ parsers/                 # –ü–∞—Ä—Å–µ—Ä–∏ –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö —Ñ–æ—Ä–º–∞—Ç—ñ–≤
‚îÇ   ‚îú‚îÄ‚îÄ chunking/                # –°—Ç—Ä–∞—Ç–µ–≥—ñ—ó —á–∞–Ω–∫—ñ–Ω–≥—É
‚îÇ   ‚îú‚îÄ‚îÄ metadata/                # –ú–µ—Ç–∞–¥–∞–Ω—ñ —Ç–∞ –∑–±–∞–≥–∞—á–µ–Ω–Ω—è
‚îÇ   ‚îî‚îÄ‚îÄ document_processor.py    # –ì–æ–ª–æ–≤–Ω–∏–π –ø—Ä–æ—Ü–µ—Å–æ—Ä
‚îú‚îÄ‚îÄ vectorization/               # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/              # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –µ–º–±–µ–¥–∏–Ω–≥—ñ–≤
‚îÇ   ‚îú‚îÄ‚îÄ batch_processor.py       # –ë–∞—Ç—á–µ–≤–∞ –æ–±—Ä–æ–±–∫–∞
‚îÇ   ‚îî‚îÄ‚îÄ vector_cache.py          # –ö–µ—à—É–≤–∞–Ω–Ω—è –≤–µ–∫—Ç–æ—Ä—ñ–≤
‚îî‚îÄ‚îÄ vector_stores/               # –í–µ–∫—Ç–æ—Ä–Ω—ñ —Å—Ö–æ–≤–∏—â–∞
    ‚îú‚îÄ‚îÄ schemas/                 # –°—Ö–µ–º–∏ –¥–∞–Ω–∏—Ö
    ‚îú‚îÄ‚îÄ backends/                # –†—ñ–∑–Ω—ñ –±–µ–∫–µ–Ω–¥–∏
    ‚îî‚îÄ‚îÄ search/                  # –ü–æ—à—É–∫ —Ç–∞ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è
```

## üöÄ –®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç

### –ë–∞–∑–æ–≤–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è

```python
from src.data_pipeline.document_processing import DocumentProcessor
from src.data_pipeline.vectorization import HuggingFaceEmbedder, EmbeddingConfig

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ø—Ä–æ—Ü–µ—Å–æ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
processor = DocumentProcessor()

# –û–±—Ä–æ–±–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
result = processor.process_file("document.pdf")
print(f"–°—Ç–≤–æ—Ä–µ–Ω–æ {len(result.chunks)} —á–∞–Ω–∫—ñ–≤")

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –µ–º–±–µ–¥–µ—Ä–∞
config = EmbeddingConfig(
    model_name="all-MiniLM-L6-v2",
    model_provider="huggingface",
    embedding_dimension=384
)
embedder = HuggingFaceEmbedder(config)

# –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –µ–º–±–µ–¥–∏–Ω–≥—ñ–≤
embedding_result = embedder.embed_text("–ü—Ä–∏–∫–ª–∞–¥ —Ç–µ–∫—Å—Ç—É")
print(f"–†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∞: {len(embedding_result.embedding)}")
```

### –ü–æ–≤–Ω–∏–π –ø–∞–π–ø–ª–∞–π–Ω

```python
from src.data_pipeline.document_processing import DocumentProcessor
from src.data_pipeline.vectorization import BatchVectorProcessor
from src.data_pipeline.vector_stores.schemas import DocumentVectorSchema

# –û–±—Ä–æ–±–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
processor = DocumentProcessor()
doc_result = processor.process_file("document.pdf")

# –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è —á–∞–Ω–∫—ñ–≤
batch_processor = BatchVectorProcessor(embedder)
vector_result = batch_processor.process_chunks(doc_result.chunks)

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤–µ–∫—Ç–æ—Ä–Ω–∏—Ö –∑–∞–ø–∏—Å—ñ–≤
schema = DocumentVectorSchema(store_config)
vector_records = []
for chunk, embedding in zip(doc_result.chunks, vector_result.results):
    if embedding:
        record = schema.create_record(
            chunk_metadata=chunk.metadata,
            document_metadata=doc_result.get_metadata(),
            vector=embedding.embedding,
            embedding_model=embedding.model_name
        )
        vector_records.append(record)
```

## üìñ –î–µ—Ç–∞–ª—å–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è

### –û–±—Ä–æ–±–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤

#### –ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ —Ñ–æ—Ä–º–∞—Ç–∏
- **PDF** - –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º PyPDF2 –∞–±–æ pdfplumber
- **DOCX** - –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º python-docx
- **HTML** - –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º BeautifulSoup4
- **Markdown** - –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é front matter
- **TXT** - –∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è–º –∫–æ–¥—É–≤–∞–Ω–Ω—è

#### –°—Ç—Ä–∞—Ç–µ–≥—ñ—ó —á–∞–Ω–∫—ñ–Ω–≥—É
- **TextChunker** - –±–∞–∑–æ–≤–∏–π —á–∞–Ω–∫—ñ–Ω–≥ –∑–∞ —Ä–æ–∑–º—ñ—Ä–æ–º
- **SemanticChunker** - —Å–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π —á–∞–Ω–∫—ñ–Ω–≥ (–≤ —Ä–æ–∑—Ä–æ–±—Ü—ñ)
- **AdaptiveChunker** - –∞–¥–∞–ø—Ç–∏–≤–Ω–∏–π —á–∞–Ω–∫—ñ–Ω–≥ –∑–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ —Ç–µ–∫—Å—Ç—É

#### –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è

```python
from src.data_pipeline.document_processing import (
    DocumentProcessingConfig, ParsingConfig, ChunkingConfig
)

parsing_config = ParsingConfig(
    extract_metadata=True,
    extract_tables=True,
    normalize_whitespace=True
)

chunking_config = ChunkingConfig(
    chunk_size=1000,
    chunk_overlap=200,
    strategy="text",
    preserve_sentences=True
)

config = DocumentProcessingConfig(
    parsing_config=parsing_config,
    chunking_config=chunking_config,
    enable_chunking=True,
    enable_metadata_enrichment=True
)
```

### –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è

#### –ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∏
- **OpenAI** - text-embedding-3-small, text-embedding-3-large
- **HuggingFace** - sentence-transformers —Ç–∞ transformers
- **Cloudflare AI** - BGE –º–æ–¥–µ–ª—ñ

#### –ë–∞—Ç—á–µ–≤–∞ –æ–±—Ä–æ–±–∫–∞

```python
from src.data_pipeline.vectorization import (
    BatchVectorProcessor, BatchProcessingConfig
)

batch_config = BatchProcessingConfig(
    batch_size=32,
    max_workers=4,
    enable_caching=True,
    show_progress=True
)

processor = BatchVectorProcessor(embedder, batch_config)
result = processor.process_texts(texts)
```

#### –ö–µ—à—É–≤–∞–Ω–Ω—è

```python
from src.data_pipeline.vectorization import VectorCache, CacheConfig

cache_config = CacheConfig(
    backend="file",  # –∞–±–æ "memory", "redis"
    cache_dir="cache/vectors",
    ttl=86400,  # 24 –≥–æ–¥–∏–Ω–∏
    max_size=10000
)

cache = VectorCache(cache_config)
```

### –í–µ–∫—Ç–æ—Ä–Ω—ñ —Å—Ö–æ–≤–∏—â–∞

#### –°—Ö–µ–º–∏ –¥–∞–Ω–∏—Ö

```python
from src.data_pipeline.vector_stores.schemas import (
    DocumentVectorSchema, VectorStoreConfig
)

store_config = VectorStoreConfig(
    store_type="chroma",
    collection_name="documents",
    embedding_dimension=384,
    distance_metric="cosine"
)

schema = DocumentVectorSchema(store_config)
```

#### –ü–æ—à—É–∫ —Ç–∞ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è

```python
from src.data_pipeline.vector_stores.schemas import (
    SearchQuery, SearchFilters, SearchType
)

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ñ—ñ–ª—å—Ç—Ä—ñ–≤
filters = SearchFilters()
filters.add_text_filter("document_type", "pdf")
filters.add_range_filter("word_count", min_value=100, max_value=1000)

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑–∞–ø–∏—Ç—É
query = SearchQuery(
    query_text="–º–∞—à–∏–Ω–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è",
    search_type=SearchType.HYBRID,
    limit=10,
    filters=filters
)
```

## ‚öôÔ∏è –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è

### –ë–∞–∑–æ–≤—ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ

```bash
pip install -r requirements.txt
```

### –î–æ–¥–∞—Ç–∫–æ–≤—ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ

```bash
# –î–ª—è PDF –æ–±—Ä–æ–±–∫–∏
pip install PyPDF2 pdfplumber

# –î–ª—è DOCX –æ–±—Ä–æ–±–∫–∏  
pip install python-docx

# –î–ª—è HTML –æ–±—Ä–æ–±–∫–∏
pip install beautifulsoup4 html2text

# –î–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—ó
pip install sentence-transformers transformers torch
pip install openai  # –¥–ª—è OpenAI –µ–º–±–µ–¥–∏–Ω–≥—ñ–≤

# –î–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–∏—Ö —Å—Ö–æ–≤–∏—â
pip install chromadb faiss-cpu pinecone-client weaviate-client
```

## üîß –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è

### –ó–º—ñ–Ω–Ω—ñ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞

```bash
# OpenAI
OPENAI_API_KEY=your_openai_api_key

# Cloudflare
CLOUDFLARE_ACCOUNT_ID=your_account_id
CLOUDFLARE_API_TOKEN=your_api_token

# Redis (–¥–ª—è –∫–µ—à—É–≤–∞–Ω–Ω—è)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your_password
```

## üìä –ü—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –±–∞—Ç—á–µ–≤—É –æ–±—Ä–æ–±–∫—É –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö –æ–±—Å—è–≥—ñ–≤
- –£–≤—ñ–º–∫–Ω—ñ—Ç—å –∫–µ—à—É–≤–∞–Ω–Ω—è –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–∏—Ö –æ–±—Ä–æ–±–æ–∫
- –ù–∞–ª–∞—à—Ç—É–π—Ç–µ —Ä–æ–∑–º—ñ—Ä —á–∞–Ω–∫—ñ–≤ –ø—ñ–¥ –≤–∞—à—É –º–æ–¥–µ–ª—å –µ–º–±–µ–¥–∏–Ω–≥—ñ–≤
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–∏–π —á–∞–Ω–∫—ñ–Ω–≥ –¥–ª—è —Ä—ñ–∑–Ω–æ—Ä—ñ–¥–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É

### –ë–µ–Ω—á–º–∞—Ä–∫–∏
- –û–±—Ä–æ–±–∫–∞ PDF: ~10-50 —Å—Ç–æ—Ä—ñ–Ω–æ–∫/—Å–µ–∫
- –ß–∞–Ω–∫—ñ–Ω–≥: ~1000-5000 —á–∞–Ω–∫—ñ–≤/—Å–µ–∫  
- –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è (HuggingFace): ~100-500 —Ç–µ–∫—Å—Ç—ñ–≤/—Å–µ–∫
- –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è (OpenAI): ~50-200 —Ç–µ–∫—Å—Ç—ñ–≤/—Å–µ–∫ (–∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ API –ª—ñ–º—ñ—Ç—ñ–≤)

## üß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è

```bash
# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–∫–ª–∞–¥—ñ–≤
python examples/document_processing_example.py
python examples/complete_pipeline_example.py

# –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç—ñ–≤
pytest tests/
```

## ü§ù –†–æ–∑—à–∏—Ä–µ–Ω–Ω—è

### –î–æ–¥–∞–≤–∞–Ω–Ω—è –Ω–æ–≤–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞

```python
from src.data_pipeline.document_processing.parsers import BaseParser

class CustomParser(BaseParser):
    @property
    def supported_types(self):
        return [DocumentType.CUSTOM]
    
    @property  
    def supported_extensions(self):
        return ['custom']
    
    def _parse_file_impl(self, file_path):
        # –í–∞—à–∞ –ª–æ–≥—ñ–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É
        pass
```

### –î–æ–¥–∞–≤–∞–Ω–Ω—è –Ω–æ–≤–æ–≥–æ –µ–º–±–µ–¥–µ—Ä–∞

```python
from src.data_pipeline.vectorization.embeddings import BaseEmbedder

class CustomEmbedder(BaseEmbedder):
    def embed_text(self, text):
        # –í–∞—à–∞ –ª–æ–≥—ñ–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –µ–º–±–µ–¥–∏–Ω–≥—ñ–≤
        pass
    
    def embed_batch(self, texts):
        # –ë–∞—Ç—á–µ–≤–∞ –æ–±—Ä–æ–±–∫–∞
        pass
```

## üìù –õ—ñ—Ü–µ–Ω–∑—ñ—è

MIT License - –¥–∏–≤—ñ—Ç—å—Å—è —Ñ–∞–π–ª LICENSE –¥–ª—è –¥–µ—Ç–∞–ª–µ–π.

## üÜò –ü—ñ–¥—Ç—Ä–∏–º–∫–∞

–î–ª—è –ø–∏—Ç–∞–Ω—å —Ç–∞ –ø—Ä–æ–±–ª–µ–º —Å—Ç–≤–æ—Ä—é–π—Ç–µ issue –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ—ó –∞–±–æ –∑–≤–µ—Ä—Ç–∞–π—Ç–µ—Å—è –¥–æ –∫–æ–º–∞–Ω–¥–∏ —Ä–æ–∑—Ä–æ–±–∫–∏.
