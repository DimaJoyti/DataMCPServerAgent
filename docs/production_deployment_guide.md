# Production Deployment Guide

## üöÄ DataMCPServerAgent Production Deployment

–≠—Ç–æ—Ç –≥–∏–¥ –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ø–æ–ª–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ DataMCPServerAgent —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π RL —Å–∏—Å—Ç–µ–º–æ–π –≤ production —Å—Ä–µ–¥–µ.

## üìã –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

### –°–∏—Å—Ç–µ–º–Ω—ã–µ –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
- **OS**: Linux (Ubuntu 20.04+), macOS, Windows 10+
- **Python**: 3.9+
- **RAM**: –ú–∏–Ω–∏–º—É–º 8GB, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 16GB+
- **CPU**: 4+ cores, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 8+ cores
- **GPU**: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è RL –æ–±—É—á–µ–Ω–∏—è
- **–î–∏—Å–∫**: 50GB+ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞

### –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
```bash
# –û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install torch torchvision torchaudio
pip install langchain-anthropic
pip install fastapi uvicorn
pip install optuna
pip install numpy pandas scikit-learn
pip install rich typer
pip install asyncio aiofiles
pip install websockets
pip install prometheus-client
```

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –û–∫—Ä—É–∂–µ–Ω–∏—è

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `.env` —Å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏:

```bash
# API Keys
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# RL Configuration
RL_MODE=modern_deep
RL_ALGORITHM=dqn
STATE_REPRESENTATION=contextual
RL_TRAINING_ENABLED=true
RL_EVALUATION_EPISODES=10
RL_SAVE_FREQUENCY=100

# Safety Configuration
RL_SAFETY_ENABLED=true
SAFE_MAX_RESOURCE_USAGE=0.8
SAFE_MAX_RESPONSE_TIME=5.0
SAFE_WEIGHT=0.5

# Explainability Configuration
RL_EXPLANATION_ENABLED=true
EXPLAINABLE_METHODS=gradient,permutation

# Distributed Configuration
DISTRIBUTED_WORKERS=4
PARAMETER_SERVER_HOST=localhost
PARAMETER_SERVER_PORT=8000

# Multi-Agent Configuration
MULTI_AGENT_COUNT=3
MULTI_AGENT_MODE=cooperative
MULTI_AGENT_COMMUNICATION=true

# Database Configuration
RL_DB_PATH=production_rl_memory.db

# Monitoring Configuration
METRICS_RETENTION_DAYS=30
DASHBOARD_UPDATE_INTERVAL=30

# API Configuration
API_HOST=0.0.0.0
API_PORT=8002
API_WORKERS=4

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE=logs/datamcp.log
```

### Docker Configuration

–°–æ–∑–¥–∞–π—Ç–µ `Dockerfile`:

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

# Create necessary directories
RUN mkdir -p logs models data

# Expose port
EXPOSE 8002

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8002/health || exit 1

# Run application
CMD ["python", "app/main_consolidated.py", "api", "--host", "0.0.0.0", "--port", "8002"]
```

–°–æ–∑–¥–∞–π—Ç–µ `docker-compose.yml`:

```yaml
version: '3.8'

services:
  datamcp-agent:
    build: .
    ports:
      - "8002:8002"
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - RL_MODE=modern_deep
      - RL_TRAINING_ENABLED=true
      - RL_SAFETY_ENABLED=true
      - RL_EXPLANATION_ENABLED=true
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./models:/app/models
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana:/etc/grafana/provisioning
    restart: unless-stopped

volumes:
  redis_data:
  prometheus_data:
  grafana_data:
```

## üöÄ –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

### 1. –õ–æ–∫–∞–ª—å–Ω–æ–µ –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
git clone <repository-url>
cd DataMCPServerAgent

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -r requirements.txt

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
cp .env.example .env
# –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ .env —Ñ–∞–π–ª

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
python app/main_consolidated.py migrate

# –ó–∞–ø—É—Å–∫ API —Å–µ—Ä–≤–µ—Ä–∞
python app/main_consolidated.py api --host 0.0.0.0 --port 8002

# –ó–∞–ø—É—Å–∫ CLI (–≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ)
python app/main_consolidated.py cli
```

### 2. Docker –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

```bash
# –°–±–æ—Ä–∫–∞ –∏ –∑–∞–ø—É—Å–∫
docker-compose up -d

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
docker-compose ps

# –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤
docker-compose logs -f datamcp-agent

# –û—Å—Ç–∞–Ω–æ–≤–∫–∞
docker-compose down
```

### 3. Kubernetes –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

–°–æ–∑–¥–∞–π—Ç–µ `k8s/deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: datamcp-agent
  labels:
    app: datamcp-agent
spec:
  replicas: 3
  selector:
    matchLabels:
      app: datamcp-agent
  template:
    metadata:
      labels:
        app: datamcp-agent
    spec:
      containers:
      - name: datamcp-agent
        image: datamcp-agent:latest
        ports:
        - containerPort: 8002
        env:
        - name: ANTHROPIC_API_KEY
          valueFrom:
            secretKeyRef:
              name: datamcp-secrets
              key: anthropic-api-key
        - name: RL_MODE
          value: "modern_deep"
        - name: RL_TRAINING_ENABLED
          value: "true"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8002
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8002
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: datamcp-agent-service
spec:
  selector:
    app: datamcp-agent
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8002
  type: LoadBalancer
```

–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ:

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–∫—Ä–µ—Ç–æ–≤
kubectl create secret generic datamcp-secrets \
  --from-literal=anthropic-api-key=your_key_here

# –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ
kubectl apply -f k8s/

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
kubectl get pods -l app=datamcp-agent
kubectl get services
```

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

### Prometheus –ú–µ—Ç—Ä–∏–∫–∏

–°–æ–∑–¥–∞–π—Ç–µ `monitoring/prometheus.yml`:

```yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'datamcp-agent'
    static_configs:
      - targets: ['datamcp-agent:8002']
    metrics_path: '/metrics'
    scrape_interval: 10s

  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
```

### Grafana Dashboard

–û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞:

- **System Metrics**:
  - CPU –∏ Memory usage
  - Request rate –∏ latency
  - Error rate
  - Uptime

- **RL Metrics**:
  - Training episodes
  - Reward trends
  - Loss trends
  - Action distribution

- **Safety Metrics**:
  - Constraint violations
  - Safety scores
  - Risk assessments

- **Performance Metrics**:
  - Response times (P50, P95, P99)
  - Throughput
  - SLA compliance

### –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è:

```python
# app/core/logging_production.py
import logging
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        
        if hasattr(record, 'rl_mode'):
            log_entry["rl_mode"] = record.rl_mode
        
        if hasattr(record, 'request_id'):
            log_entry["request_id"] = record.request_id
        
        if record.exc_info:
            log_entry["exception"] = self.formatException(record.exc_info)
        
        return json.dumps(log_entry)
```

## üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

### API Security

```python
# app/core/security.py
from fastapi import HTTPException, Depends, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import jwt

security = HTTPBearer()

async def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    try:
        payload = jwt.decode(
            credentials.credentials, 
            SECRET_KEY, 
            algorithms=["HS256"]
        )
        return payload
    except jwt.PyJWTError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid authentication credentials"
        )
```

### Rate Limiting

```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)

@app.route("/api/rl/process")
@limiter.limit("10/minute")
async def process_request(request: Request):
    # Process request
    pass
```

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### Unit Tests

```bash
# –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤
python -m pytest tests/ -v

# –¢–µ—Å—Ç—ã —Å –ø–æ–∫—Ä—ã—Ç–∏–µ–º
python -m pytest tests/ --cov=app --cov-report=html

# –¢–µ—Å—Ç—ã RL —Å–∏—Å—Ç–µ–º—ã
python -m pytest tests/test_rl/ -v
```

### Integration Tests

```bash
# API —Ç–µ—Å—Ç—ã
python -m pytest tests/integration/test_api.py -v

# RL –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
python -m pytest tests/integration/test_rl_integration.py -v
```

### Load Testing

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ locust
pip install locust

# –ó–∞–ø—É—Å–∫ –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
locust -f tests/load/locustfile.py --host=http://localhost:8002
```

## üìà –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

1. **Load Balancer**: Nginx –∏–ª–∏ HAProxy
2. **Multiple Instances**: Docker Swarm –∏–ª–∏ Kubernetes
3. **Database Sharding**: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
4. **Caching**: Redis –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è

### –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

1. **CPU**: –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ cores
2. **Memory**: –ë–æ–ª—å—à–µ RAM –¥–ª—è –º–æ–¥–µ–ª–µ–π
3. **GPU**: –î–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è RL –æ–±—É—á–µ–Ω–∏—è
4. **Storage**: SSD –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º

## üîß –û–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ

### –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –ó–∞–¥–∞—á–∏

```bash
# –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏
0 2 * * * /app/scripts/daily_maintenance.sh

# –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏
0 3 * * 0 /app/scripts/weekly_maintenance.sh

# –ï–∂–µ–º–µ—Å—è—á–Ω—ã–µ –∑–∞–¥–∞—á–∏
0 4 1 * * /app/scripts/monthly_maintenance.sh
```

### Backup Strategy

```bash
#!/bin/bash
# scripts/backup.sh

# Backup database
cp data/production_rl_memory.db backups/rl_memory_$(date +%Y%m%d).db

# Backup models
tar -czf backups/models_$(date +%Y%m%d).tar.gz models/

# Backup logs
tar -czf backups/logs_$(date +%Y%m%d).tar.gz logs/

# Clean old backups (keep 30 days)
find backups/ -name "*.db" -mtime +30 -delete
find backups/ -name "*.tar.gz" -mtime +30 -delete
```

## üö® Troubleshooting

### –û–±—â–∏–µ –ü—Ä–æ–±–ª–µ–º—ã

1. **High Memory Usage**:
   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–µ–π RL
   - –ù–∞—Å—Ç—Ä–æ–π—Ç–µ garbage collection
   - –£–º–µ–Ω—å—à–∏—Ç–µ batch size

2. **Slow Response Times**:
   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ CPU usage
   - –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ RL inference
   - –î–æ–±–∞–≤—å—Ç–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ

3. **Training Issues**:
   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ learning rate
   - –í–∞–ª–∏–¥–∏—Ä—É–π—Ç–µ –¥–∞–Ω–Ω—ã–µ
   - –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ loss trends

### –õ–æ–≥–∏ –∏ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã
python app/main_consolidated.py status

# –ü—Ä–æ–≤–µ—Ä–∫–∞ RL —Å–∏—Å—Ç–µ–º—ã
python app/main_consolidated.py rl status

# –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤
tail -f logs/datamcp.log

# –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
python scripts/performance_analysis.py
```

## üéØ Best Practices

1. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥**: –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∞–ª–µ—Ä—Ç—ã –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫
2. **Backup**: –†–µ–≥—É–ª—è—Ä–Ω–æ–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ
3. **Security**: –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
4. **Testing**: –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
5. **Documentation**: –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –≤ –∞–∫—Ç—É–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏
6. **Capacity Planning**: –ü–ª–∞–Ω–∏—Ä—É–π—Ç–µ —Ä–µ—Å—É—Ä—Å—ã –∑–∞—Ä–∞–Ω–µ–µ
7. **Disaster Recovery**: –ü–ª–∞–Ω –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ —Å–±–æ–µ–≤

## üìû –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏:

1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
2. –ü—Ä–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
3. –°–æ–∑–¥–∞–π—Ç–µ issue –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
4. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∫–æ–º–∞–Ω–¥–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

---

**–°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ production —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—é! üöÄ**
