#!/usr/bin/env python3
"""
DataMCPServerAgent Monitoring System Demo

Demonstrates all monitoring capabilities and generates sample reports.
"""

import asyncio
import json
import sys
from datetime import datetime
from pathlib import Path

# Add project root to Python path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def print_header(title: str):
    """Print a formatted header"""
    print(f"\n{'='*60}")
    print(f"  {title}")
    print(f"{'='*60}")


def print_section(title: str):
    """Print a formatted section header"""
    print(f"\n{'-'*40}")
    print(f"  {title}")
    print(f"{'-'*40}")


async def demo_monitoring_system():
    """Demonstrate the complete monitoring system"""

    print_header("DataMCPServerAgent Monitoring System Demo")
    print("This demo showcases all monitoring capabilities")
    print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # 1. Configuration Demo
    print_section("1. Configuration Management")

    try:
        from monitoring.core.config import MonitoringConfig

        # Create configuration from environment
        config = MonitoringConfig.from_env()
        print("‚úÖ Configuration loaded successfully")
        print(f"   Project root: {config.project_root}")
        print(f"   Data directory: {config.data_directory}")
        print(f"   Dashboard enabled: {config.dashboard.enabled}")

        # Validate configuration
        issues = config.validate()
        if issues:
            print("‚ö†Ô∏è  Configuration issues:")
            for issue in issues:
                print(f"   - {issue}")
        else:
            print("‚úÖ Configuration validation passed")

    except Exception as e:
        print(f"‚ùå Configuration error: {e}")
        return

    # 2. Code Quality Demo
    print_section("2. Code Quality Monitoring")

    try:
        from monitoring.code_quality.quality_monitor import monitor_code_quality

        print("üîç Running code quality analysis...")
        quality_report = monitor_code_quality(
            project_root=".",
            directories=["app", "src", "examples", "scripts"],
            output_path="monitoring/data/demo_quality_report.json"
        )

        print("‚úÖ Code Quality Analysis Complete")
        print(f"   Overall Score: {quality_report.overall_score}/100")
        print(f"   Total Issues: {quality_report.total_issues}")
        print(f"   Critical Issues: {quality_report.critical_issues}")

        if quality_report.tool_results:
            print("   Tool Results:")
            for tool, metrics in quality_report.tool_results.items():
                print(f"     {tool}: {metrics.status} ({metrics.issues_count} issues)")

    except Exception as e:
        print(f"‚ùå Code quality monitoring error: {e}")

    # 3. Security Monitoring Demo
    print_section("3. Security Monitoring")

    try:
        from monitoring.security.security_monitor import monitor_security

        print("üîí Running security analysis...")
        security_report = monitor_security(
            project_root=".",
            directories=["app", "src", "examples", "scripts"],
            output_path="monitoring/data/demo_security_report.json"
        )

        print("‚úÖ Security Analysis Complete")
        print(f"   Risk Score: {security_report.overall_risk_score}/100")
        print(f"   Total Issues: {security_report.total_issues}")
        print(f"   Critical: {security_report.critical_issues}")
        print(f"   High: {security_report.high_issues}")
        print(f"   Medium: {security_report.medium_issues}")
        print(f"   Low: {security_report.low_issues}")

        if security_report.recommendations:
            print("   Top Recommendations:")
            for rec in security_report.recommendations[:3]:
                print(f"     ‚Ä¢ {rec}")

    except Exception as e:
        print(f"‚ùå Security monitoring error: {e}")

    # 4. Testing Metrics Demo
    print_section("4. Testing Metrics")

    try:
        from monitoring.testing.coverage_monitor import monitor_testing

        print("üß™ Running testing analysis...")
        test_report = monitor_testing(
            project_root=".",
            output_path="monitoring/data/demo_test_report.json"
        )

        print("‚úÖ Testing Analysis Complete")
        print(f"   Health Score: {test_report.health_score}/100")
        print(f"   Coverage: {test_report.coverage_metrics.overall_coverage:.1f}%")
        print(f"   Total Tests: {test_report.performance_metrics.total_tests}")
        print(f"   Passed: {test_report.performance_metrics.passed_tests}")
        print(f"   Failed: {test_report.performance_metrics.failed_tests}")

        if test_report.recommendations:
            print("   Recommendations:")
            for rec in test_report.recommendations[:3]:
                print(f"     ‚Ä¢ {rec}")

    except Exception as e:
        print(f"‚ùå Testing monitoring error: {e}")

    # 5. Documentation Health Demo
    print_section("5. Documentation Health")

    try:
        from monitoring.documentation.doc_health_checker import monitor_documentation_health

        print("üìö Running documentation analysis...")
        doc_report = monitor_documentation_health(
            project_root=".",
            docs_directories=["docs", "README.md"],
            output_path="monitoring/data/demo_doc_report.json"
        )

        print("‚úÖ Documentation Analysis Complete")
        print(f"   Overall Score: {doc_report.overall_score:.1f}/100")
        print(f"   Coverage: {doc_report.coverage_score:.1f}/100")
        print(f"   Quality: {doc_report.quality_score:.1f}/100")
        print(f"   Freshness: {doc_report.freshness_score:.1f}/100")
        print(f"   Total Documents: {doc_report.total_documents}")
        print(f"   Broken Links: {doc_report.total_broken_links}")

        if doc_report.recommendations:
            print("   Recommendations:")
            for rec in doc_report.recommendations[:3]:
                print(f"     ‚Ä¢ {rec}")

    except Exception as e:
        print(f"‚ùå Documentation monitoring error: {e}")

    # 6. CI/CD Monitoring Demo (if GitHub token available)
    print_section("6. CI/CD Performance Monitoring")

    try:
        import os
        github_token = os.getenv("GITHUB_TOKEN")

        if github_token:
            from monitoring.ci_cd.performance_monitor import monitor_cicd_performance

            print("üîÑ Running CI/CD analysis...")
            cicd_metrics = await monitor_cicd_performance(
                github_token=github_token,
                owner="DimaJoyti",
                repo="DataMCPServerAgent",
                output_path="monitoring/data/demo_cicd_metrics.json"
            )

            print("‚úÖ CI/CD Analysis Complete")
            print(f"   Workflows analyzed: {len(cicd_metrics)}")

            for workflow_name, metrics in cicd_metrics.items():
                print(f"   {workflow_name}:")
                print(f"     Success Rate: {metrics.success_rate:.1f}%")
                print(f"     Avg Duration: {metrics.average_duration_seconds:.1f}s")
                print(f"     Recent Failures: {len(metrics.recent_failures)}")
        else:
            print("‚ö†Ô∏è  GitHub token not available - skipping CI/CD monitoring")
            print("   Set GITHUB_TOKEN environment variable to enable this feature")

    except Exception as e:
        print(f"‚ùå CI/CD monitoring error: {e}")

    # 7. Dashboard Demo
    print_section("7. Web Dashboard")

    try:
        from monitoring.dashboard.main_dashboard import MonitoringDashboard

        print("üåê Dashboard capabilities:")
        print("   ‚úÖ Real-time metrics visualization")
        print("   ‚úÖ Interactive charts and graphs")
        print("   ‚úÖ WebSocket live updates")
        print("   ‚úÖ Mobile-responsive design")
        print("   ‚úÖ Historical data tracking")

        # Create dashboard instance (don't start server in demo)
        dashboard = MonitoringDashboard("monitoring/data")
        print("   ‚úÖ Dashboard components initialized")
        print("   üìä To start dashboard: python -m monitoring.dashboard.main_dashboard")

    except ImportError:
        print("‚ö†Ô∏è  Dashboard dependencies not available")
        print("   Install with: pip install fastapi uvicorn jinja2")
    except Exception as e:
        print(f"‚ùå Dashboard error: {e}")

    # 8. Scheduler Demo
    print_section("8. Automated Scheduling")

    try:
        from monitoring.core.scheduler import MonitoringScheduler

        scheduler = MonitoringScheduler(config)
        scheduler.setup_default_tasks()

        print("‚è∞ Scheduler capabilities:")
        print("   ‚úÖ Automated task scheduling")
        print("   ‚úÖ Configurable intervals")
        print("   ‚úÖ Error handling and retry")
        print("   ‚úÖ Manual task triggering")

        status = scheduler.get_task_status()
        print(f"   üìã Total tasks: {status['total_tasks']}")
        print(f"   ‚úÖ Enabled tasks: {status['enabled_tasks']}")

        print("   Configured tasks:")
        for task_name, task_info in status['tasks'].items():
            if task_info['enabled']:
                print(f"     ‚Ä¢ {task_name}: every {task_info['interval_minutes']} minutes")

    except Exception as e:
        print(f"‚ùå Scheduler error: {e}")

    # 9. Summary Report
    print_section("9. System Summary")

    try:
        # Generate overall summary
        summary = {
            "timestamp": datetime.now().isoformat(),
            "demo_completed": True,
            "components_tested": [
                "Configuration Management",
                "Code Quality Monitoring",
                "Security Monitoring",
                "Testing Metrics",
                "Documentation Health",
                "Dashboard Components",
                "Automated Scheduling"
            ],
            "system_health": {},
            "recommendations": []
        }

        # Load generated reports
        data_dir = Path("monitoring/data")
        if data_dir.exists():
            report_files = {
                "quality": "demo_quality_report.json",
                "security": "demo_security_report.json",
                "testing": "demo_test_report.json",
                "documentation": "demo_doc_report.json"
            }

            for report_type, filename in report_files.items():
                file_path = data_dir / filename
                if file_path.exists():
                    with open(file_path) as f:
                        report_data = json.load(f)

                    if report_type == "quality":
                        summary["system_health"]["code_quality"] = report_data.get("overall_score", 0)
                    elif report_type == "security":
                        summary["system_health"]["security_risk"] = report_data.get("overall_risk_score", 0)
                    elif report_type == "testing":
                        summary["system_health"]["test_health"] = report_data.get("health_score", 0)
                    elif report_type == "documentation":
                        summary["system_health"]["doc_health"] = report_data["scores"]["overall_score"]

                    # Collect recommendations
                    recommendations = report_data.get("recommendations", [])
                    for rec in recommendations[:2]:
                        summary["recommendations"].append(f"[{report_type.title()}] {rec}")

        # Save summary
        summary_file = data_dir / "demo_summary.json"
        summary_file.parent.mkdir(parents=True, exist_ok=True)
        with open(summary_file, 'w') as f:
            json.dump(summary, f, indent=2)

        print("üìä Demo Summary:")
        print("   ‚úÖ All components tested successfully")
        print(f"   üìÅ Reports saved to: {data_dir}")

        if summary["system_health"]:
            print("   üìà Health Scores:")
            for metric, score in summary["system_health"].items():
                status_icon = "‚úÖ" if score >= 80 else "‚ö†Ô∏è" if score >= 60 else "‚ùå"
                print(f"     {status_icon} {metric.replace('_', ' ').title()}: {score:.1f}")

        if summary["recommendations"]:
            print("   üí° Key Recommendations:")
            for rec in summary["recommendations"][:5]:
                print(f"     ‚Ä¢ {rec}")

    except Exception as e:
        print(f"‚ùå Summary generation error: {e}")

    # 10. Next Steps
    print_section("10. Next Steps")

    print("üöÄ To start using the monitoring system:")
    print("   1. Set environment variables (GITHUB_TOKEN, etc.)")
    print("   2. Install dependencies: pip install -r monitoring/requirements.txt")
    print("   3. Start monitoring: python scripts/start_monitoring.py")
    print("   4. Access dashboard: http://localhost:8080")
    print()
    print("üìö Documentation:")
    print("   ‚Ä¢ Full guide: monitoring/README.md")
    print("   ‚Ä¢ Configuration: monitoring/config.json")
    print("   ‚Ä¢ Data directory: monitoring/data/")
    print()
    print("üîß Customization:")
    print("   ‚Ä¢ Modify monitoring intervals in config")
    print("   ‚Ä¢ Add custom monitoring tasks")
    print("   ‚Ä¢ Configure notifications (Slack, Discord)")
    print("   ‚Ä¢ Set up alerting thresholds")

    print_header("Demo Complete!")
    print("The DataMCPServerAgent monitoring system is ready for production use.")


if __name__ == "__main__":
    asyncio.run(demo_monitoring_system())
